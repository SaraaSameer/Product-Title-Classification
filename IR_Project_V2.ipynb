{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OIpzlsY6tkQ2"
   },
   "outputs": [],
   "source": [
    "import sys#THIS IS FOR GOOGLE COLAB USERS ONLY\n",
    "from google.colab import files\n",
    "sys.path.insert(0,'/content/drive/MyDrive/IR-Project-Colab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YTFbtZ6TuUF5"
   },
   "outputs": [],
   "source": [
    "!cp /content/drive/MyDrive/IR-Project-Colab/Utilities.py /content #THIS IS FOR GOOGLE COLAB USERS ONLY\n",
    "!cp /content/drive/MyDrive/IR-Project-Colab/KNNImpute.py /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "#------ Additional Lib\n",
    "import neattext as nt\n",
    "import neattext.functions as nfx\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer   # Turning textual data into numeric for computation\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder               # For encoding categorical target attr\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm   # Baseline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# ------- Validation metrics\n",
    "from sklearn.metrics import accuracy_score    \n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import hamming_loss                  \n",
    "from sklearn.metrics import classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "b9Bn9ZgWfNFa"
   },
   "outputs": [],
   "source": [
    "# import Utilities  #THIS IS FOR GOOGLE COLAB USERS ONLY\n",
    "# import KNNImpute\n",
    "\n",
    "from Utilities import *\n",
    "from KNNImpute import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "Gyf-YFzxekAr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Computer\n",
      "[nltk_data]     Point\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Adana Gallery Suri Square Hijab – Light Pink <...\n",
      "1        Cuba Heartbreaker Eau De Parfum Spray 100ml/3....\n",
      "2        Andoer 150cm Cellphone Smartphone Mini Dual-He...\n",
      "3        ANMYNA Complaint Silky Set 柔顺洗发配套 (Shampoo 520...\n",
      "4        Argital Argiltubo Green Clay For Face and Body...\n",
      "                               ...                        \n",
      "36278    SADES K10 LED Backlit Wired USB Mechanical Gam...\n",
      "36279    SONA 20L Electric Oven SEO 2220 <ul> <li>&nbsp...\n",
      "36280    OP1001 Portable Wireless Bluetooth 2.1 Speaker...\n",
      "36281    Woot-Woot TicTacToe Pillow Case (White) <ul> <...\n",
      "36282    New Smart Wristband D21 Smart Bracelet Heart R...\n",
      "Name: titleDescp, Length: 36283, dtype: object\n",
      "category_lvl1       0\n",
      "category_lvl2       0\n",
      "category_lvl3    2135\n",
      "titleDescp          0\n",
      "dtype: int64\n",
      "\n",
      "The missing data percent is: 1.4710746079431138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Computer Point\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category_lvl1    0\n",
      "category_lvl2    0\n",
      "category_lvl3    0\n",
      "Title_desc       0\n",
      "dtype: int64\n",
      "\n",
      "The missing data percent is: 0.0\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "nltk.download('stopwords')\n",
    "import pandas as pd\n",
    "labels=[\"country\", \"sku_id\", \"title\", \"category_lvl1\",\"category_lvl2\",\"category_lvl3\", \"description\", \"price\", \"type\"]\n",
    "\n",
    "def getTrainingDataset():\n",
    "    return pd.read_csv('data_train.csv', header=None, names=labels)  \n",
    "\n",
    "\n",
    "def NullStatistics(df):\n",
    "    missing_val = df.isnull().sum()\n",
    "    print(missing_val)\n",
    "    total_cells = np.product(df.shape)\n",
    "    missing_percent = (missing_val.sum()/total_cells) *100\n",
    "    print(f'\\nThe missing data percent is: {missing_percent}')\n",
    "\n",
    "trainingDataset=getTrainingDataset()\n",
    "\n",
    "# train_df,Y1,Y2,Y3=Utilities.Cleaning_Data_Utility(trainingDataset) #Utilities. hatadena yahan se  COLAB\n",
    "train_df,Y1,Y2,Y3=Cleaning_Data_Utility(trainingDataset)   #NOTEBOOK USERS\n",
    "# print(train_df)\n",
    "\n",
    "NullStatistics(train_df)\n",
    "\n",
    "# unique_label_c1, unique_label_c2, unique_label_c3 = KNNImpute.preserve_label(train_df) #It has all unique values lying in ctg1 , 2 , 3 column\n",
    "unique_label_c1, unique_label_c2, unique_label_c3 = preserve_label(train_df)   #notebook\n",
    "\n",
    "# KNNImpute.encode(['category_lvl1', 'category_lvl2', 'category_lvl3'],train_df)    #Performed encoding for CTGLVL3 KNN #COLAB\n",
    "encode(['category_lvl1', 'category_lvl2', 'category_lvl3'],train_df)    #NOTEBOOK\n",
    "\n",
    "# train_df_imputed = KNNImpute.impute(train_df)  #COLAB\n",
    "train_df_imputed = impute(train_df)            #NOTEBOOK\n",
    "\n",
    "# train_df_imputed = KNNImpute.clean_csv(train_df_imputed,train_df)   #COLAB\n",
    "train_df_imputed = clean_csv(train_df_imputed,train_df)             #NOTEBOOK\n",
    "\n",
    "NullStatistics(train_df_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T6QEyq5ooDvN",
    "outputId": "255e109b-eaaa-47d3-c40a-9e22dfcd2152"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        2.0\n",
      "1        3.0\n",
      "2        7.0\n",
      "3        3.0\n",
      "4        3.0\n",
      "        ... \n",
      "36278    1.0\n",
      "36279    5.0\n",
      "36280    1.0\n",
      "36281    4.0\n",
      "36282    7.0\n",
      "Name: category_lvl1, Length: 36283, dtype: float64\n",
      "0        adana galleri suri squar hijab light pink ul l...\n",
      "1        cuba heartbreak eau de parfum spray ml oz form...\n",
      "2        andoer cm cellphon smartphon mini dual head om...\n",
      "3        anmyna complaint silki set shampoo ml conditio...\n",
      "4        argit argiltubo green clay face bodi ml ul li ...\n",
      "                               ...                        \n",
      "36278    sade k led backlit wire usb mechan game keyboa...\n",
      "36279    sona l electr oven seo ul li nbsp year warrant...\n",
      "36280    op portabl wireless bluetooth speaker hand fre...\n",
      "36281    woot woot tictacto pillow case white ul li cot...\n",
      "36282    new smart wristband smart bracelet heart rate ...\n",
      "Name: Title_desc, Length: 36283, dtype: object\n",
      "  (0, 28913)\t0.07225424844998868\n",
      "  (0, 26966)\t0.37659487115461027\n",
      "  (0, 26075)\t0.1998311858009805\n",
      "  (0, 25125)\t0.09569136097916549\n",
      "  (0, 24730)\t0.2749088614258273\n",
      "  (0, 24685)\t0.24936730479422012\n",
      "  (0, 21057)\t0.1476446166731313\n",
      "  (0, 19162)\t0.1519301323425332\n",
      "  (0, 16922)\t0.0780089820671493\n",
      "  (0, 15867)\t0.12476995284687205\n",
      "  (0, 15802)\t0.216601402357855\n",
      "  (0, 13585)\t0.26353252165855096\n",
      "  (0, 12712)\t0.28221774410096967\n",
      "  (0, 11066)\t0.31718340705761777\n",
      "  (0, 8884)\t0.20669140444780615\n",
      "  (0, 6559)\t0.16898535529139208\n",
      "  (0, 6539)\t0.21996803699368137\n",
      "  (0, 4947)\t0.20363684473882185\n",
      "  (0, 274)\t0.37659487115461027\n",
      "  (1, 27650)\t0.1629724724469635\n",
      "  (1, 26013)\t0.18366254623451603\n",
      "  (1, 25585)\t0.11212950375728589\n",
      "  (1, 25458)\t0.14501959261082673\n",
      "  (1, 25171)\t0.12734650666253478\n",
      "  (1, 23192)\t0.20554347993281055\n",
      "  :\t:\n",
      "  (36282, 12161)\t0.05780549124389509\n",
      "  (36282, 11830)\t0.05825536109758337\n",
      "  (36282, 11320)\t0.12069189206309493\n",
      "  (36282, 10944)\t0.052211882696263825\n",
      "  (36282, 10132)\t0.04890810200698313\n",
      "  (36282, 9423)\t0.09519421277329085\n",
      "  (36282, 7566)\t0.2296095837640153\n",
      "  (36282, 7546)\t0.16506659317108185\n",
      "  (36282, 6658)\t0.0713211391671284\n",
      "  (36282, 5938)\t0.052659396224827425\n",
      "  (36282, 5710)\t0.05109163575984841\n",
      "  (36282, 4045)\t0.278963602350648\n",
      "  (36282, 4023)\t0.07475566750827757\n",
      "  (36282, 4006)\t0.10639122067157139\n",
      "  (36282, 3825)\t0.12831497534741287\n",
      "  (36282, 3822)\t0.08942373930893509\n",
      "  (36282, 3551)\t0.14654091619489876\n",
      "  (36282, 3431)\t0.06688679555603681\n",
      "  (36282, 3132)\t0.06093927143515811\n",
      "  (36282, 2288)\t0.12113797673844014\n",
      "  (36282, 1959)\t0.0665353600443563\n",
      "  (36282, 1109)\t0.18820730037820457\n",
      "  (36282, 645)\t0.07547548750826906\n",
      "  (36282, 237)\t0.07458974591153449\n",
      "  (36282, 177)\t0.09596402180067315\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = train_df_imputed['Title_desc']\n",
    "Y1 = train_df_imputed['category_lvl1']\n",
    "Y2 = train_df_imputed['category_lvl2']\n",
    "Y3 = train_df_imputed['category_lvl3']\n",
    "print(Y1)\n",
    "print(X)\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X)\n",
    "X_tfidf = vectorizer.transform(X)\n",
    "print(X_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***CATEGORY 1 ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20539    2.0\n",
      "6557     7.0\n",
      "12710    3.0\n",
      "12054    2.0\n",
      "3503     8.0\n",
      "        ... \n",
      "28094    7.0\n",
      "22842    0.0\n",
      "12094    2.0\n",
      "25228    8.0\n",
      "32451    8.0\n",
      "Name: category_lvl1, Length: 25398, dtype: float64\n",
      "(25398, 31798)\n",
      "(10885, 31798)\n",
      "[6. 7. 4. ... 5. 6. 2.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, Y1, test_size=0.3, stratify= Y1, random_state=42)\n",
    "print(y_train)\n",
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "\n",
    "SVM_Classfier=SVC(kernel='linear' , random_state=0)\n",
    "model1 = SVM_Classfier.fit(X_train,y_train)\n",
    "Y_Pred1=model1.predict(X_test)\n",
    "print(Y_Pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score with linear kernel is : \n",
      "92.76067983463481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.91      0.93       586\n",
      "         1.0       0.93      0.87      0.90       878\n",
      "         2.0       0.96      0.96      0.96      1719\n",
      "         3.0       0.95      0.92      0.94      1212\n",
      "         4.0       0.84      0.93      0.89      1814\n",
      "         5.0       0.90      0.82      0.86       475\n",
      "         6.0       0.95      0.97      0.96      2183\n",
      "         7.0       0.88      0.85      0.87       753\n",
      "         8.0       0.97      0.95      0.96      1265\n",
      "\n",
      "    accuracy                           0.93     10885\n",
      "   macro avg       0.93      0.91      0.92     10885\n",
      "weighted avg       0.93      0.93      0.93     10885\n",
      "\n",
      "[[ 533    6    4    0   21    0   18    3    1]\n",
      " [   5  764    0    6   24    4   37   38    0]\n",
      " [   0    2 1652   11   37    1    1    1   14]\n",
      " [   0    1   18 1119   67    3    1    1    2]\n",
      " [   2   10   25   23 1691   29    9   13   12]\n",
      " [   0    1    1    7   72  391    0    2    1]\n",
      " [   8   14    3    4   21    5 2109   19    0]\n",
      " [   9   23    1    2   35    0   35  640    8]\n",
      " [   1    2   14    6   35    0    0    9 1198]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Accuracy score with linear kernel is : ')\n",
    "print(metrics.accuracy_score(y_test,Y_Pred1)*100)\n",
    "# print(f' F1 Score with linear Kernel is: {f1_score(y_test, Y_Pred)*100}')\n",
    "print(classification_report(y_test, Y_Pred1))\n",
    "mat = confusion_matrix(y_test, Y_Pred1)\n",
    "print(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tntadjFIdYvS"
   },
   "source": [
    "***CATEGORY 2 ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gUb0hZ5Jwlu4",
    "outputId": "9e0f2ad8-9469-42ca-b6ea-f72615ca9070"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1585     46.0\n",
      "23952    24.0\n",
      "9668     24.0\n",
      "8845      7.0\n",
      "15114    47.0\n",
      "         ... \n",
      "24955     0.0\n",
      "27752    30.0\n",
      "33144    17.0\n",
      "16965    25.0\n",
      "6625     34.0\n",
      "Name: category_lvl2, Length: 25398, dtype: float64\n",
      "(25398, 31798)\n",
      "(10885, 31798)\n",
      "[56. 35. 54. ...  8. 27. 35.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, Y2, test_size=0.3, stratify= Y2, random_state=42)\n",
    "print(y_train)\n",
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "\n",
    "SVM_Classfier=SVC(kernel='linear' , random_state=0)\n",
    "model2= SVM_Classfier.fit(X_train,y_train)\n",
    "Y_Pred2=model2.predict(X_test)\n",
    "print(Y_Pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AtHdroeXnzpE",
    "outputId": "b1102bdb-18b1-43bd-b33b-1806dbdf3492"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score with linear kernel is : \n",
      "86.10932475884245\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.97      0.94      2071\n",
      "         1.0       0.78      0.83      0.80       350\n",
      "         2.0       0.83      0.72      0.77        72\n",
      "         3.0       0.64      0.69      0.67       100\n",
      "         4.0       0.77      0.71      0.74       128\n",
      "         5.0       0.90      0.88      0.89       107\n",
      "         6.0       0.71      0.26      0.38        19\n",
      "         7.0       0.86      0.84      0.85       235\n",
      "         8.0       0.86      0.82      0.84       444\n",
      "         9.0       0.97      0.89      0.93        36\n",
      "        10.0       0.77      0.88      0.83       104\n",
      "        11.0       1.00      0.75      0.86        16\n",
      "        12.0       0.94      0.45      0.61        33\n",
      "        13.0       0.88      0.82      0.85        17\n",
      "        14.0       0.97      0.99      0.98       134\n",
      "        15.0       0.92      0.85      0.89       137\n",
      "        16.0       0.99      0.92      0.95       103\n",
      "        17.0       0.86      0.69      0.76       121\n",
      "        18.0       0.97      0.78      0.87        46\n",
      "        19.0       0.92      0.91      0.92       152\n",
      "        20.0       0.89      0.73      0.80        75\n",
      "        21.0       1.00      0.88      0.93        48\n",
      "        22.0       0.90      0.56      0.69        34\n",
      "        23.0       0.87      0.83      0.85       128\n",
      "        24.0       0.88      0.84      0.86       358\n",
      "        25.0       0.59      0.78      0.67       378\n",
      "        26.0       0.86      0.82      0.84        22\n",
      "        27.0       0.94      0.94      0.94       512\n",
      "        28.0       0.77      0.82      0.79       302\n",
      "        29.0       0.89      0.86      0.88        73\n",
      "        30.0       0.98      0.82      0.89       103\n",
      "        31.0       0.78      0.78      0.78        77\n",
      "        32.0       0.84      0.86      0.85       158\n",
      "        33.0       0.92      0.89      0.90       274\n",
      "        34.0       0.79      0.59      0.68        91\n",
      "        35.0       0.90      0.80      0.84       483\n",
      "        36.0       0.80      0.37      0.51        54\n",
      "        37.0       0.73      0.69      0.71        16\n",
      "        38.0       0.82      0.91      0.86        87\n",
      "        39.0       0.92      0.56      0.70        43\n",
      "        40.0       0.74      0.33      0.45        61\n",
      "        41.0       1.00      0.70      0.82        30\n",
      "        42.0       0.67      0.59      0.62        17\n",
      "        43.0       0.95      0.91      0.93        67\n",
      "        44.0       0.72      0.82      0.77       167\n",
      "        45.0       0.86      0.81      0.84       198\n",
      "        46.0       0.76      0.65      0.70       160\n",
      "        47.0       0.95      0.93      0.94       181\n",
      "        48.0       0.71      0.59      0.64        98\n",
      "        49.0       0.70      0.46      0.55        57\n",
      "        50.0       0.78      0.28      0.41        25\n",
      "        51.0       0.97      0.84      0.90        37\n",
      "        52.0       0.84      0.84      0.84        43\n",
      "        53.0       0.89      0.71      0.79        56\n",
      "        54.0       0.97      0.97      0.97       619\n",
      "        55.0       0.93      0.84      0.88       145\n",
      "        56.0       0.83      0.94      0.88      1183\n",
      "\n",
      "    accuracy                           0.86     10885\n",
      "   macro avg       0.86      0.76      0.79     10885\n",
      "weighted avg       0.86      0.86      0.86     10885\n",
      "\n",
      "[[2007   10    0 ...    0    1    1]\n",
      " [  24  292    0 ...    0    1    2]\n",
      " [   1    0   52 ...    0    0    0]\n",
      " ...\n",
      " [   3    1    0 ...  598    6    5]\n",
      " [   6    2    0 ...    8  122    3]\n",
      " [   8    0    0 ...    1    0 1114]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('Accuracy score with linear kernel is : ')\n",
    "print(metrics.accuracy_score(y_test,Y_Pred2)*100)\n",
    "# print(f' F1 Score with linear Kernel is: {f1_score(y_test, Y_Pred)*100}')\n",
    "print(classification_report(y_test, Y_Pred2))\n",
    "mat = confusion_matrix(y_test, Y_Pred2)\n",
    "print(mat)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***CATEGORY 3 ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18877     61.0\n",
      "4562       1.0\n",
      "28997    112.0\n",
      "31983     14.0\n",
      "5567      50.0\n",
      "         ...  \n",
      "28520     29.0\n",
      "8776      31.0\n",
      "34173    125.0\n",
      "29604    179.0\n",
      "314      125.0\n",
      "Name: category_lvl3, Length: 25398, dtype: float64\n",
      "(25398, 31798)\n",
      "(10885, 31798)\n",
      "[ 84.  61.  24. ...  31. 115. 179.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, Y3, test_size=0.3, stratify= Y3, random_state=42)\n",
    "print(y_train)\n",
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "\n",
    "SVM_Classfier=SVC(kernel='linear' , random_state=0)\n",
    "model3 = SVM_Classfier.fit(X_train,y_train)\n",
    "Y_Pred3= model3.predict(X_test)\n",
    "print(Y_Pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score with linear kernel is : \n",
      "76.45383555351401\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.62      0.61        16\n",
      "         1.0       0.78      0.78      0.78       171\n",
      "         2.0       0.73      0.70      0.72        27\n",
      "         3.0       0.44      0.39      0.41        36\n",
      "         4.0       0.83      0.59      0.69        17\n",
      "         5.0       0.96      0.84      0.90        32\n",
      "         6.0       0.75      0.38      0.50        16\n",
      "         7.0       0.79      0.63      0.70        35\n",
      "         8.0       0.47      0.38      0.42        42\n",
      "         9.0       0.88      0.94      0.91       262\n",
      "        10.0       0.70      0.75      0.72        51\n",
      "        11.0       0.69      0.47      0.56        19\n",
      "        12.0       0.79      0.51      0.62        37\n",
      "        13.0       0.89      0.76      0.82        21\n",
      "        14.0       0.70      0.65      0.67       133\n",
      "        15.0       0.90      0.91      0.91       102\n",
      "        16.0       0.67      0.46      0.55        26\n",
      "        17.0       0.94      0.92      0.93        36\n",
      "        18.0       0.73      0.73      0.73        22\n",
      "        19.0       0.54      0.50      0.52        26\n",
      "        20.0       0.59      0.90      0.72        21\n",
      "        21.0       0.64      0.45      0.53        31\n",
      "        22.0       0.65      0.50      0.57        30\n",
      "        23.0       0.50      0.04      0.08        23\n",
      "        24.0       0.44      0.48      0.46       113\n",
      "        25.0       0.74      0.61      0.67        38\n",
      "        26.0       0.83      0.66      0.74        65\n",
      "        27.0       0.97      0.88      0.92        41\n",
      "        28.0       0.23      0.08      0.11        65\n",
      "        29.0       0.90      0.82      0.86        44\n",
      "        30.0       0.41      0.63      0.50        27\n",
      "        31.0       0.84      0.97      0.90       762\n",
      "        32.0       0.71      0.63      0.67        19\n",
      "        33.0       0.64      0.39      0.48        18\n",
      "        34.0       0.91      0.77      0.83        26\n",
      "        35.0       0.81      0.72      0.76        18\n",
      "        36.0       0.79      0.58      0.67        19\n",
      "        37.0       0.62      0.43      0.51        23\n",
      "        38.0       0.97      0.97      0.97        33\n",
      "        39.0       1.00      0.52      0.69        23\n",
      "        40.0       0.53      0.42      0.47        19\n",
      "        41.0       0.50      0.22      0.30        23\n",
      "        42.0       1.00      0.91      0.95        22\n",
      "        43.0       0.40      0.53      0.46        59\n",
      "        44.0       1.00      0.75      0.86        28\n",
      "        45.0       0.74      0.65      0.69        26\n",
      "        46.0       0.74      0.81      0.77        36\n",
      "        47.0       0.74      0.68      0.71        47\n",
      "        48.0       0.54      0.43      0.48        30\n",
      "        49.0       0.76      0.92      0.83        38\n",
      "        50.0       0.91      0.77      0.83        78\n",
      "        51.0       0.67      0.27      0.38        15\n",
      "        52.0       0.78      0.60      0.68        30\n",
      "        53.0       1.00      0.79      0.88        14\n",
      "        54.0       0.85      0.79      0.81        14\n",
      "        55.0       0.31      0.13      0.19        38\n",
      "        56.0       0.80      0.75      0.77        16\n",
      "        57.0       0.74      0.68      0.71        50\n",
      "        58.0       0.93      0.67      0.78        21\n",
      "        59.0       1.00      0.75      0.86        12\n",
      "        60.0       0.89      0.94      0.91        17\n",
      "        61.0       0.70      0.81      0.75        48\n",
      "        62.0       0.91      0.53      0.67        19\n",
      "        63.0       0.77      0.50      0.61        20\n",
      "        64.0       0.86      0.83      0.85        36\n",
      "        65.0       0.60      0.69      0.64        26\n",
      "        66.0       0.89      0.81      0.85        21\n",
      "        67.0       0.77      0.45      0.57        22\n",
      "        68.0       0.48      0.46      0.47        50\n",
      "        69.0       0.67      0.29      0.40        35\n",
      "        70.0       0.87      0.87      0.87       163\n",
      "        71.0       0.56      0.19      0.29        26\n",
      "        72.0       0.90      0.86      0.88        21\n",
      "        73.0       0.50      0.42      0.46        52\n",
      "        74.0       0.69      0.41      0.51        27\n",
      "        75.0       1.00      0.67      0.80        15\n",
      "        76.0       0.57      0.61      0.59        46\n",
      "        77.0       0.72      0.72      0.72        18\n",
      "        78.0       0.93      0.95      0.94        40\n",
      "        79.0       0.71      0.63      0.67        19\n",
      "        80.0       0.89      0.89      0.89        18\n",
      "        81.0       0.89      0.84      0.86        19\n",
      "        82.0       0.80      0.86      0.83        51\n",
      "        83.0       0.93      0.42      0.58        31\n",
      "        84.0       0.40      0.63      0.49        92\n",
      "        85.0       0.82      0.68      0.74        34\n",
      "        86.0       0.63      0.64      0.64        56\n",
      "        87.0       0.44      0.59      0.50        86\n",
      "        88.0       0.71      0.89      0.79        19\n",
      "        89.0       0.70      0.54      0.61        26\n",
      "        90.0       0.64      0.71      0.67        38\n",
      "        91.0       0.92      0.77      0.84        31\n",
      "        92.0       0.48      0.69      0.57        62\n",
      "        93.0       0.88      0.76      0.81       103\n",
      "        94.0       0.79      0.80      0.79        69\n",
      "        95.0       0.77      0.67      0.71        30\n",
      "        96.0       0.62      0.50      0.55        32\n",
      "        97.0       0.79      0.79      0.79        29\n",
      "        98.0       1.00      0.67      0.80        15\n",
      "        99.0       0.76      0.71      0.74        73\n",
      "       100.0       0.38      0.18      0.24        17\n",
      "       101.0       0.87      0.81      0.84        16\n",
      "       102.0       0.58      0.67      0.62        27\n",
      "       103.0       0.75      0.78      0.77        23\n",
      "       104.0       0.50      0.18      0.27        11\n",
      "       105.0       0.92      0.87      0.89        39\n",
      "       106.0       0.82      0.77      0.79       441\n",
      "       107.0       0.81      0.87      0.84        30\n",
      "       108.0       0.87      0.91      0.89        45\n",
      "       109.0       0.80      0.84      0.82        19\n",
      "       110.0       0.50      0.29      0.36        14\n",
      "       111.0       0.53      0.44      0.48        41\n",
      "       112.0       0.94      0.91      0.93        34\n",
      "       113.0       0.91      0.82      0.86       124\n",
      "       114.0       0.92      0.82      0.87        56\n",
      "       115.0       0.55      0.47      0.51        34\n",
      "       116.0       0.74      0.82      0.78        39\n",
      "       117.0       1.00      0.80      0.89        30\n",
      "       118.0       0.58      0.63      0.60       101\n",
      "       119.0       0.67      0.19      0.30        21\n",
      "       120.0       1.00      0.57      0.73        14\n",
      "       121.0       0.71      0.61      0.65        28\n",
      "       122.0       0.88      0.56      0.68        25\n",
      "       123.0       0.92      0.79      0.85        14\n",
      "       124.0       0.61      0.61      0.61        23\n",
      "       125.0       0.91      0.99      0.95      1225\n",
      "       126.0       0.84      0.87      0.85        30\n",
      "       127.0       0.77      0.59      0.67        17\n",
      "       128.0       0.82      0.59      0.69        39\n",
      "       129.0       0.45      0.63      0.53       425\n",
      "       130.0       0.91      0.98      0.95        53\n",
      "       131.0       0.88      0.47      0.61        32\n",
      "       132.0       0.67      0.49      0.56        41\n",
      "       133.0       1.00      0.70      0.83        27\n",
      "       134.0       0.82      0.70      0.76        20\n",
      "       135.0       1.00      0.95      0.97        19\n",
      "       136.0       1.00      0.88      0.94        17\n",
      "       137.0       0.79      0.81      0.80        27\n",
      "       138.0       0.88      0.75      0.81        20\n",
      "       139.0       0.81      0.87      0.84        30\n",
      "       140.0       0.55      0.40      0.46        53\n",
      "       141.0       0.69      0.73      0.71        15\n",
      "       142.0       0.50      0.39      0.44        38\n",
      "       143.0       0.95      0.92      0.94       126\n",
      "       144.0       0.86      0.86      0.86        42\n",
      "       145.0       0.82      0.88      0.85        16\n",
      "       146.0       0.60      0.69      0.64        58\n",
      "       147.0       0.73      0.71      0.72        34\n",
      "       148.0       0.83      0.78      0.81        32\n",
      "       149.0       0.98      0.94      0.96       249\n",
      "       150.0       0.60      0.58      0.59        43\n",
      "       151.0       0.91      0.59      0.71        17\n",
      "       152.0       0.88      0.66      0.75        58\n",
      "       153.0       0.65      0.76      0.70        34\n",
      "       154.0       0.74      0.78      0.76        18\n",
      "       155.0       0.71      0.25      0.37        20\n",
      "       156.0       0.64      0.41      0.50        17\n",
      "       157.0       0.67      0.46      0.55        26\n",
      "       158.0       0.89      0.86      0.87        56\n",
      "       159.0       0.66      0.68      0.67        76\n",
      "       160.0       0.87      0.59      0.70        22\n",
      "       161.0       0.94      0.91      0.93        68\n",
      "       162.0       0.58      0.49      0.53        72\n",
      "       163.0       0.83      0.67      0.74        15\n",
      "       164.0       0.79      0.66      0.72        35\n",
      "       165.0       0.56      0.58      0.57        26\n",
      "       166.0       0.55      0.45      0.49        51\n",
      "       167.0       1.00      0.77      0.87        22\n",
      "       168.0       1.00      0.96      0.98        26\n",
      "       169.0       0.94      0.79      0.86        19\n",
      "       170.0       0.90      0.89      0.89       149\n",
      "       171.0       0.56      0.56      0.56        57\n",
      "       172.0       0.90      0.87      0.88       135\n",
      "       173.0       0.94      0.84      0.89        19\n",
      "       174.0       1.00      0.88      0.94        17\n",
      "       175.0       0.87      0.81      0.84        16\n",
      "       176.0       0.75      0.44      0.56        27\n",
      "       177.0       0.65      0.87      0.75        63\n",
      "       178.0       0.69      0.39      0.50        23\n",
      "       179.0       0.74      0.90      0.81       793\n",
      "       180.0       0.79      0.70      0.75        27\n",
      "       181.0       0.67      0.64      0.65        25\n",
      "       182.0       0.80      0.60      0.69        20\n",
      "       183.0       0.89      0.64      0.74        25\n",
      "\n",
      "    accuracy                           0.76     10885\n",
      "   macro avg       0.76      0.66      0.69     10885\n",
      "weighted avg       0.77      0.76      0.76     10885\n",
      "\n",
      "[[ 10   0   0 ...   0   0   0]\n",
      " [  0 134   0 ...   0   0   0]\n",
      " [  0   0  19 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...  16   0   0]\n",
      " [  0   0   0 ...   2  12   0]\n",
      " [  0   0   0 ...   0   0  16]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Accuracy score with linear kernel is : ')\n",
    "print(metrics.accuracy_score(y_test,Y_Pred3)*100)\n",
    "# print(f' F1 Score with linear Kernel is: {f1_score(y_test, Y_Pred)*100}')\n",
    "print(classification_report(y_test, Y_Pred3))\n",
    "mat = confusion_matrix(y_test, Y_Pred3)\n",
    "print(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tokyo']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le =LabelEncoder()\n",
    "le.fit([\"paris\", \"paris\", \"tokyo\", \"amsterdam\"])\n",
    "LabelEncoder()\n",
    "list(le.classes_)\n",
    "le.transform([\"tokyo\", \"tokyo\", \"paris\"])\n",
    "\n",
    "list(le.inverse_transform([2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rough Work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Fashion', 'Health & Beauty',\n",
       "       'TV, Audio / Video, Gaming & Wearables', 'Computers & Laptops',\n",
       "       'Cameras', 'Home & Living', 'Watches Sunglasses Jewellery',\n",
       "       'Mobiles & Tablets', 'Home Appliances'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_label_c1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le =LabelEncoder()\n",
    "le.fit()\n",
    "LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('train_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_lvl1</th>\n",
       "      <th>category_lvl2</th>\n",
       "      <th>category_lvl3</th>\n",
       "      <th>Title_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>adana galleri suri squar hijab light pink ul l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>cuba heartbreak eau de parfum spray ml oz form...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>andoer cm cellphon smartphon mini dual head om...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>anmyna complaint silki set shampoo ml conditio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>argit argiltubo green clay face bodi ml ul li ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36278</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>sade k led backlit wire usb mechan game keyboa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36279</th>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>sona l electr oven seo ul li nbsp year warrant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36280</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>op portabl wireless bluetooth speaker hand fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36281</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>woot woot tictacto pillow case white ul li cot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36282</th>\n",
       "      <td>7.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>new smart wristband smart bracelet heart rate ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36283 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       category_lvl1  category_lvl2  category_lvl3  \\\n",
       "0                2.0           56.0          113.0   \n",
       "1                3.0            3.0           67.0   \n",
       "2                7.0            1.0           95.0   \n",
       "3                3.0           23.0          147.0   \n",
       "4                3.0           36.0           23.0   \n",
       "...              ...            ...            ...   \n",
       "36278            1.0            8.0           82.0   \n",
       "36279            5.0           30.0          109.0   \n",
       "36280            1.0            8.0          155.0   \n",
       "36281            4.0            5.0          126.0   \n",
       "36282            7.0           55.0            2.0   \n",
       "\n",
       "                                              Title_desc  \n",
       "0      adana galleri suri squar hijab light pink ul l...  \n",
       "1      cuba heartbreak eau de parfum spray ml oz form...  \n",
       "2      andoer cm cellphon smartphon mini dual head om...  \n",
       "3      anmyna complaint silki set shampoo ml conditio...  \n",
       "4      argit argiltubo green clay face bodi ml ul li ...  \n",
       "...                                                  ...  \n",
       "36278  sade k led backlit wire usb mechan game keyboa...  \n",
       "36279  sona l electr oven seo ul li nbsp year warrant...  \n",
       "36280  op portabl wireless bluetooth speaker hand fre...  \n",
       "36281  woot woot tictacto pillow case white ul li cot...  \n",
       "36282  new smart wristband smart bracelet heart rate ...  \n",
       "\n",
       "[36283 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        adana galleri suri squar hijab light pink ul l...\n",
      "1        cuba heartbreak eau de parfum spray ml oz form...\n",
      "2        andoer cm cellphon smartphon mini dual head om...\n",
      "3        anmyna complaint silki set shampoo ml conditio...\n",
      "4        argit argiltubo green clay face bodi ml ul li ...\n",
      "                               ...                        \n",
      "36278    sade k led backlit wire usb mechan game keyboa...\n",
      "36279    sona l electr oven seo ul li nbsp year warrant...\n",
      "36280    op portabl wireless bluetooth speaker hand fre...\n",
      "36281    woot woot tictacto pillow case white ul li cot...\n",
      "36282    new smart wristband smart bracelet heart rate ...\n",
      "Name: Title_desc, Length: 36283, dtype: object\n",
      "  (0, 8884)\t0.20669140444780615\n",
      "  (0, 6539)\t0.21996803699368137\n",
      "  (0, 6559)\t0.16898535529139208\n",
      "  (0, 13585)\t0.26353252165855096\n",
      "  (0, 25125)\t0.09569136097916549\n",
      "  (0, 4947)\t0.20363684473882185\n",
      "  (0, 24730)\t0.2749088614258273\n",
      "  (0, 24685)\t0.24936730479422012\n",
      "  (0, 19162)\t0.1519301323425332\n",
      "  (0, 16922)\t0.0780089820671493\n",
      "  (0, 15802)\t0.216601402357855\n",
      "  (0, 28913)\t0.07225424844998868\n",
      "  (0, 21057)\t0.1476446166731313\n",
      "  (0, 15867)\t0.12476995284687205\n",
      "  (0, 12712)\t0.28221774410096967\n",
      "  (0, 26075)\t0.1998311858009805\n",
      "  (0, 26966)\t0.37659487115461027\n",
      "  (0, 11066)\t0.31718340705761777\n",
      "  (0, 274)\t0.37659487115461027\n",
      "  (1, 22913)\t0.2101858228151334\n",
      "  (1, 25458)\t0.14501959261082673\n",
      "  (1, 25585)\t0.11212950375728589\n",
      "  (1, 23192)\t0.20554347993281055\n",
      "  (1, 12161)\t0.2602380157370854\n",
      "  (1, 88)\t0.303246095582536\n",
      "  :\t:\n",
      "  (36282, 18054)\t0.27855632347642434\n",
      "  (36282, 7546)\t0.1650665931710819\n",
      "  (36282, 19604)\t0.18836942874220666\n",
      "  (36282, 3551)\t0.1465409161948988\n",
      "  (36282, 27971)\t0.05382190651002375\n",
      "  (36282, 6658)\t0.07132113916712843\n",
      "  (36282, 3822)\t0.08942373930893512\n",
      "  (36282, 4045)\t0.2789636023506481\n",
      "  (36282, 7566)\t0.2296095837640154\n",
      "  (36282, 26329)\t0.08495277921993491\n",
      "  (36282, 28376)\t0.1782657343221273\n",
      "  (36282, 3132)\t0.060939271435158135\n",
      "  (36282, 30960)\t0.09177080896904158\n",
      "  (36282, 237)\t0.07458974591153451\n",
      "  (36282, 3431)\t0.06688679555603684\n",
      "  (36282, 18712)\t0.06095138525959079\n",
      "  (36282, 18915)\t0.03690841389211651\n",
      "  (36282, 11830)\t0.05825536109758339\n",
      "  (36282, 24534)\t0.05078942894419843\n",
      "  (36282, 5710)\t0.05109163575984843\n",
      "  (36282, 12161)\t0.05780549124389511\n",
      "  (36282, 13585)\t0.051503279796958595\n",
      "  (36282, 15802)\t0.14110443953104965\n",
      "  (36282, 28913)\t0.028241909203603456\n",
      "  (36282, 15867)\t0.09753728687879798\n"
     ]
    }
   ],
   "source": [
    "X = test_df['Title_desc']\n",
    "v = TfidfVectorizer()\n",
    "# vectorizer.fit(X)\n",
    "print(X)\n",
    "# X_tfidf = vectorizer.transform(X)\n",
    "# print(X_tfidf)\n",
    "X = v.fit_transform(test_df['Title_desc'].values.astype('U'))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat_one = model1.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.49651351872778"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_df['category_lvl1'], y_cat_one)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat_two = model2.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.83364109913734"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_df['category_lvl2'], y_cat_two)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat_three = model3.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.10690957197585"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_df['category_lvl3'], y_cat_three)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "IR-Project-V2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
